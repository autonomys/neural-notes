{"version":3,"file":"static/js/651.366ceed4.chunk.js","mappings":"+SAqBO,SAASA,EAAgBC,GAAkD,IAEtDC,EAFcC,EAAWC,UAAAC,OAAA,QAAAC,IAAAF,UAAA,GAAAA,UAAA,GAAG,QAASG,EAAQH,UAAAC,OAAA,QAAAC,IAAAF,UAAA,GAAAA,UAAA,GAAG,KAClEI,EAAkB,GAAGC,GAAAC,EAAAA,EAAAA,GACXT,GAAQ,IAAxB,IAAAQ,EAAAE,MAAAT,EAAAO,EAAAG,KAAAC,MAA0B,KAAfC,EAACZ,EAAAa,MACJC,OAAI,EACR,GAAqB,UAAjBF,EAAEG,WACFD,EAAOb,OAEN,GAAqB,OAAjBW,EAAEG,WACPD,EAAOT,OAEN,GAAqB,WAAjBO,EAAEG,WACPD,EAAO,aAEN,IAAqB,YAAjBF,EAAEG,WAIP,MAAM,IAAIC,MAAM,iCAADC,OAAkCL,IAHjDE,EAAOF,EAAEE,IAIb,CACAR,EAAgBY,KAAK,GAADD,OAAIH,EAAI,MAAAG,OAAKL,EAAEO,MACvC,CAAC,OAAAC,GAAAb,EAAAc,EAAAD,EAAA,SAAAb,EAAAe,GAAA,CACD,OAAOhB,EAAgBiB,KAAK,KAChC,C,cCvCaC,EAAa,SAAAC,IAAAC,EAAAA,EAAAA,GAAAF,EAAAC,GAAA,IAAAE,GAAAC,EAAAA,EAAAA,GAAAJ,GACtB,SAAAA,EAAYK,GAAQ,OAAAC,EAAAA,EAAAA,GAAA,KAAAN,GAAAG,EAAAI,KAAA,KACVF,EACV,CAgDC,OAhDAG,EAAAA,EAAAA,GAAAR,EAAA,EAAAS,IAAA,WAAApB,MAAA,eAAAqB,GAAAC,EAAAA,EAAAA,IAAAC,EAAAA,EAAAA,KAAAC,MACD,SAAAC,EAAevC,EAAUwC,EAAMC,GAAS,IAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAAxC,EAAAP,EAAAgD,EAAAC,EAAAC,EAAA,YAAAd,EAAAA,EAAAA,KAAAe,MAAA,SAAAC,GAAA,cAAAA,EAAAC,KAAAD,EAAAE,MAAA,OAG8C,OAF5EZ,EAAc,GACdC,EAAa,GACbC,EAAiB7C,EAASwD,KAAI,SAACC,GAAW,OAAK1D,EAAgB0D,EAAY,IAACJ,EAAAE,KAAA,EACnDG,EAAAA,GAAAA,UAA0BjB,EAAWkB,KAAKlB,UAAW,CAAEmB,QAASD,KAAKC,UAAU,OAAxF,OAAhBd,EAAgBO,EAAAQ,KAAAR,EAAAE,KAAG,EACgB,OAAhBT,QAAgB,IAAhBA,OAAgB,EAAhBA,EAAkBgB,eAAe,CAAEC,KAAMJ,KAAKK,YAAcnB,GAAe,OAApF,OAAVE,EAAUM,EAAAQ,KAAAR,EAAAC,KAAG,EAAHD,EAAAE,KAAG,GAEOU,QAAQC,IAAIlE,EAASwD,KAAI,SAACC,GAAW,OAAKN,EAAKhB,UAAUsB,EAAajB,EAAMO,EAAW,KAAE,QAAzGC,EAAOK,EAAAQ,KAAArD,GAAAC,EAAAA,EAAAA,GACQuC,GAAO,IAA5B,IAAAxC,EAAAE,MAAAT,EAAAO,EAAAG,KAAAC,OAAWqC,EAAMhD,EAAAa,OACFqD,WACPvB,EAAWzB,KAAK8B,EAAOkB,WAE3BxB,EAAYxB,KAAK8B,EAAON,YAC3B,OAAAtB,GAAAb,EAAAc,EAAAD,EAAA,SAAAb,EAAAe,GAAA,CAAA8B,EAAAE,KAAA,wBAAAF,EAAAC,KAAA,GAAAD,EAAAe,GAAAf,EAAA,SAAAA,EAAAE,KAAA,GAGe,OAAVR,QAAU,IAAVA,OAAU,EAAVA,EAAYsB,eAAchB,EAAAe,IAAK,cAAAf,EAAAe,GAAA,QAQxC,OALKlB,EAAS,CACXP,YAAAA,EACAwB,UAAWvB,EAAWxC,OACM,QADAsC,EACtBiB,KAAKW,yBAAiB,IAAA5B,OAAA,EAAtBA,EAAAV,KAAAuC,MAAA7B,EAAA,CAAAiB,MAAIzC,OAAwB0B,SAC5BvC,GACTgD,EAAAE,KAAA,GACe,OAAVR,QAAU,IAAVA,OAAU,EAAVA,EAAYyB,aAAatB,GAAO,QAInC,OAHHuB,OAAOC,eAAexB,EAAQyB,EAAAA,GAAS,CACnC7D,MAAOiC,EAAa,CAAE6B,MAAiB,OAAV7B,QAAU,IAAVA,OAAU,EAAVA,EAAY6B,YAAUvE,EACnDwE,cAAc,IACfxB,EAAAyB,OAAA,SACI5B,GAAM,yBAAAG,EAAAb,OAAA,GAAAD,EAAA,mBAChB,gBAAAwC,EAAAC,EAAAC,GAAA,OAAA9C,EAAAoC,MAAA,KAAApE,UAAA,EAhCA,IAgCA,CAAA+B,IAAA,aAAApB,MACD,WACI,MAAO,iBACX,GAAC,CAAAoB,IAAA,iBAAApB,MAAA,eAAAoE,GAAA9C,EAAAA,EAAAA,IAAAC,EAAAA,EAAAA,KAAAC,MACD,SAAA6C,EAAqBC,EAAc5C,EAAMC,GAAS,IAAA4C,EAAA,OAAAhD,EAAAA,EAAAA,KAAAe,MAAA,SAAAkC,GAAA,cAAAA,EAAAhC,KAAAgC,EAAA/B,MAAA,OACwC,OAAhF8B,EAAiBD,EAAa5B,KAAI,SAAC+B,GAAW,OAAKA,EAAYC,gBAAgB,IAACF,EAAAR,OAAA,SAC/EnB,KAAK8B,SAASJ,EAAgB7C,EAAMC,IAAU,wBAAA6C,EAAA9C,OAAA,GAAA2C,EAAA,UACxD,gBAAAO,EAAAC,EAAAC,GAAA,OAAAV,EAAAX,MAAA,KAAApE,UAAA,EAJA,IAIA,CAAA+B,IAAA,OAAApB,MAAA,eAAA+E,GAAAzD,EAAAA,EAAAA,IAAAC,EAAAA,EAAAA,KAAAC,MACD,SAAAwD,EAAW9F,EAAUwC,EAAMC,GAAS,IAAAQ,EAAAN,EAAA,OAAAN,EAAAA,EAAAA,KAAAe,MAAA,SAAA2C,GAAA,cAAAA,EAAAzC,KAAAyC,EAAAxC,MAAA,cAAAwC,EAAAxC,KAAA,EACXI,KAAK8B,SAAS,CAACzF,GAAWwC,EAAMC,GAAU,OACzB,OADhCQ,EAAM8C,EAAAlC,KACNlB,EAAcM,EAAON,YAAWoD,EAAAjB,OAAA,SAC/BnC,EAAY,GAAG,GAAGqD,SAAO,wBAAAD,EAAAvD,OAAA,GAAAsD,EAAA,UACnC,gBAAAG,EAAAC,EAAAC,GAAA,OAAAN,EAAAtB,MAAA,KAAApE,UAAA,EALA,IAKA,CAAA+B,IAAA,aAAApB,MAAA,eAAAsF,GAAAhE,EAAAA,EAAAA,IAAAC,EAAAA,EAAAA,KAAAC,MACD,SAAA+D,EAAiBd,EAAa/C,EAAMC,GAAS,IAAA4C,EAAA,OAAAhD,EAAAA,EAAAA,KAAAe,MAAA,SAAAkD,GAAA,cAAAA,EAAAhD,KAAAgD,EAAA/C,MAAA,OACU,OAA7C8B,EAAiBE,EAAYC,iBAAgBc,EAAAxB,OAAA,SAC5CnB,KAAK3B,KAAKqD,EAAgB7C,EAAMC,IAAU,wBAAA6D,EAAA9D,OAAA,GAAA6D,EAAA,UACpD,gBAAAE,EAAAC,EAAAC,GAAA,OAAAL,EAAA7B,MAAA,KAAApE,UAAA,EAJA,MAIAsB,CAAA,CAnDqB,CAASiF,EAAAA,G,UCEnC,SAASC,EAAwBC,GAC7B,OAAQA,GACJ,IAAK,SACD,MAAO,SACX,IAAK,KACD,MAAO,YACX,IAAK,QACD,MAAO,OACX,QACI,MAAM,IAAI3F,MAAM,yBAADC,OAA0B0F,IAErD,CACA,SAASC,EAA4B9F,EAAMK,GACvC,OAAQL,GACJ,IAAK,OACD,OAAO,IAAI+F,EAAAA,EAAiB1F,GAChC,IAAK,YACD,OAAO,IAAI2F,EAAAA,GAAc3F,GAC7B,IAAK,SACD,OAAO,IAAI4F,EAAAA,EAAkB5F,GACjC,QACI,OAAO,IAAI6F,EAAAA,EAAY7F,EAAU,OAAJL,QAAI,IAAJA,EAAAA,EAAQ,WAEjD,CAmBO,IAAMmG,EAAU,SAAAC,IAAAxF,EAAAA,EAAAA,GAAAuF,EAAAC,GAAA,IAAAvF,GAAAC,EAAAA,EAAAA,GAAAqF,GACnB,SAAAA,EAAYpF,EAAQsF,GAAe,IAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAAnF,GAAApB,EAAAA,EAAAA,GAAA,KAAAmF,GAC/B/D,EAAAvB,EAAAI,KAAA,KAAY,OAANF,QAAM,IAANA,EAAAA,EAAU,CAAC,GACjB2C,OAAOC,gBAAc6D,EAAAA,EAAAA,GAAApF,GAAO,cAAe,CACvCqF,YAAY,EACZ3D,cAAc,EACd4D,UAAU,EACV3H,MAAO,IAEX2D,OAAOC,gBAAc6D,EAAAA,EAAAA,GAAApF,GAAO,OAAQ,CAChCqF,YAAY,EACZ3D,cAAc,EACd4D,UAAU,EACV3H,MAAO,IAEX2D,OAAOC,gBAAc6D,EAAAA,EAAAA,GAAApF,GAAO,mBAAoB,CAC5CqF,YAAY,EACZ3D,cAAc,EACd4D,UAAU,EACV3H,MAAO,IAEX2D,OAAOC,gBAAc6D,EAAAA,EAAAA,GAAApF,GAAO,kBAAmB,CAC3CqF,YAAY,EACZ3D,cAAc,EACd4D,UAAU,EACV3H,MAAO,IAEX2D,OAAOC,gBAAc6D,EAAAA,EAAAA,GAAApF,GAAO,IAAK,CAC7BqF,YAAY,EACZ3D,cAAc,EACd4D,UAAU,EACV3H,MAAO,IAEX2D,OAAOC,gBAAc6D,EAAAA,EAAAA,GAAApF,GAAO,YAAa,CACrCqF,YAAY,EACZ3D,cAAc,EACd4D,UAAU,EACV3H,WAAO,IAEX2D,OAAOC,gBAAc6D,EAAAA,EAAAA,GAAApF,GAAO,YAAa,CACrCqF,YAAY,EACZ3D,cAAc,EACd4D,UAAU,EACV3H,MAAO,kBAEX2D,OAAOC,gBAAc6D,EAAAA,EAAAA,GAAApF,GAAO,cAAe,CACvCqF,YAAY,EACZ3D,cAAc,EACd4D,UAAU,EACV3H,WAAO,IAEX2D,OAAOC,gBAAc6D,EAAAA,EAAAA,GAAApF,GAAO,OAAQ,CAChCqF,YAAY,EACZ3D,cAAc,EACd4D,UAAU,EACV3H,WAAO,IAEX2D,OAAOC,gBAAc6D,EAAAA,EAAAA,GAAApF,GAAO,UAAW,CACnCqF,YAAY,EACZ3D,cAAc,EACd4D,UAAU,EACV3H,WAAO,IAEX2D,OAAOC,gBAAc6D,EAAAA,EAAAA,GAAApF,GAAO,YAAa,CACrCqF,YAAY,EACZ3D,cAAc,EACd4D,UAAU,EACV3H,OAAO,IAEX2D,OAAOC,gBAAc6D,EAAAA,EAAAA,GAAApF,GAAO,YAAa,CACrCqF,YAAY,EACZ3D,cAAc,EACd4D,UAAU,EACV3H,WAAO,IAEX2D,OAAOC,gBAAc6D,EAAAA,EAAAA,GAAApF,GAAO,wBAAyB,CACjDqF,YAAY,EACZ3D,cAAc,EACd4D,UAAU,EACV3H,WAAO,IAEX2D,OAAOC,gBAAc6D,EAAAA,EAAAA,GAAApF,GAAO,oBAAqB,CAC7CqF,YAAY,EACZ3D,cAAc,EACd4D,UAAU,EACV3H,WAAO,IAEX2D,OAAOC,gBAAc6D,EAAAA,EAAAA,GAAApF,GAAO,6BAA8B,CACtDqF,YAAY,EACZ3D,cAAc,EACd4D,UAAU,EACV3H,WAAO,IAEX2D,OAAOC,gBAAc6D,EAAAA,EAAAA,GAAApF,GAAO,+BAAgC,CACxDqF,YAAY,EACZ3D,cAAc,EACd4D,UAAU,EACV3H,WAAO,IAEX2D,OAAOC,gBAAc6D,EAAAA,EAAAA,GAAApF,GAAO,SAAU,CAClCqF,YAAY,EACZ3D,cAAc,EACd4D,UAAU,EACV3H,WAAO,IAEX2D,OAAOC,gBAAc6D,EAAAA,EAAAA,GAAApF,GAAO,eAAgB,CACxCqF,YAAY,EACZ3D,cAAc,EACd4D,UAAU,EACV3H,WAAO,IAEX,IAAM4H,EAA6B,QAAvBrB,EAAS,OAANvF,QAAM,IAANA,OAAM,EAANA,EAAQ6G,oBAAY,IAAAtB,EAAAA,EACX,qBAAZuB,QAEW,QADbtB,EACEsB,CAAAA,SAAAA,aAAAA,WAAAA,gBAAAA,qBAAAA,EAAAA,qBAAAA,EAAAA,qBAAAA,EAAAA,cAAAA,UAAW,IAAAtB,OAAA,EAAXA,EAAauB,oBACfxI,EACJyI,EAAuC,QAA5BvB,EAAS,OAANzF,QAAM,IAANA,OAAM,EAANA,EAAQiH,yBAAiB,IAAAxB,EAAAA,EACrB,qBAAZqB,QAEW,QADbpB,EACEoB,CAAAA,SAAAA,aAAAA,WAAAA,gBAAAA,qBAAAA,EAAAA,qBAAAA,EAAAA,qBAAAA,EAAAA,cAAAA,UAAW,IAAApB,OAAA,EAAXA,EAAawB,0BACf3I,EACV,IAAKyI,IAAgBJ,EACjB,MAAM,IAAIzH,MAAM,oCAEpB,IAAMgI,EAAyD,QAArCxB,EAAS,OAAN3F,QAAM,IAANA,OAAM,EAANA,EAAQoH,kCAA0B,IAAAzB,EAAAA,EACvC,qBAAZmB,QAEW,QADblB,EACEkB,CAAAA,SAAAA,aAAAA,WAAAA,gBAAAA,qBAAAA,EAAAA,qBAAAA,EAAAA,qBAAAA,EAAAA,cAAAA,UAAW,IAAAlB,OAAA,EAAXA,EAAayB,oCACf9I,EACJ+I,EAA6D,QAAvCzB,EAAS,OAAN7F,QAAM,IAANA,OAAM,EAANA,EAAQuH,oCAA4B,IAAA1B,EAAAA,EAC3C,qBAAZiB,QAEW,QADbhB,EACEgB,CAAAA,SAAAA,aAAAA,WAAAA,gBAAAA,qBAAAA,EAAAA,qBAAAA,EAAAA,qBAAAA,EAAAA,cAAAA,UAAW,IAAAhB,OAAA,EAAXA,EAAa0B,sCACfjJ,EACJkJ,EAA+C,QAAhC1B,EAAS,OAAN/F,QAAM,IAANA,OAAM,EAANA,EAAQ0H,6BAAqB,IAAA3B,EAAAA,EAC7B,qBAAZe,QAEW,QADbd,EACEc,CAAAA,SAAAA,aAAAA,WAAAA,gBAAAA,qBAAAA,EAAAA,qBAAAA,EAAAA,qBAAAA,EAAAA,cAAAA,UAAW,IAAAd,OAAA,EAAXA,EAAa2B,8BACfpJ,EAiBV,GAhBA8C,EAAKuG,UAA6B,QAApB3B,EAAS,OAANjG,QAAM,IAANA,OAAM,EAANA,EAAQ4H,iBAAS,IAAA3B,EAAAA,EAAI5E,EAAKuG,UAC3CvG,EAAKwG,YAAiC,QAAtB3B,EAAS,OAANlG,QAAM,IAANA,OAAM,EAANA,EAAQ6H,mBAAW,IAAA3B,EAAAA,EAAI,CAAC,EAC3C7E,EAAKyG,QAAgB,OAAN9H,QAAM,IAANA,OAAM,EAANA,EAAQ8H,QACvBzG,EAAK0G,YAAiC,QAAtB5B,EAAS,OAANnG,QAAM,IAANA,OAAM,EAANA,EAAQ+H,mBAAW,IAAA5B,EAAAA,EAAI9E,EAAK0G,YAC/C1G,EAAK2G,KAAmB,QAAf5B,EAAS,OAANpG,QAAM,IAANA,OAAM,EAANA,EAAQgI,YAAI,IAAA5B,EAAAA,EAAI/E,EAAK2G,KACjC3G,EAAK4G,iBAA2C,QAA3B5B,EAAS,OAANrG,QAAM,IAANA,OAAM,EAANA,EAAQiI,wBAAgB,IAAA5B,EAAAA,EAAIhF,EAAK4G,iBACzD5G,EAAK6G,gBAAyC,QAA1B5B,EAAS,OAANtG,QAAM,IAANA,OAAM,EAANA,EAAQkI,uBAAe,IAAA5B,EAAAA,EAAIjF,EAAK6G,gBACvD7G,EAAK8G,UAAkB,OAANnI,QAAM,IAANA,OAAM,EAANA,EAAQmI,UACzB9G,EAAKxC,EAAa,QAAZ0H,EAAS,OAANvG,QAAM,IAANA,OAAM,EAANA,EAAQnB,SAAC,IAAA0H,EAAAA,EAAIlF,EAAKxC,EAC3BwC,EAAK+G,UAAkB,OAANpI,QAAM,IAANA,OAAM,EAANA,EAAQoI,UACzB/G,EAAKX,KAAa,OAANV,QAAM,IAANA,OAAM,EAANA,EAAQU,KACpBW,EAAKgH,UAA6B,QAApB7B,EAAS,OAANxG,QAAM,IAANA,OAAM,EAANA,EAAQqI,iBAAS,IAAA7B,GAAAA,EAClCnF,EAAKqG,sBAAwBD,EAC7BpG,EAAK4F,kBAAoBD,EACzB3F,EAAK+F,2BAA6BD,EAClC9F,EAAKkG,6BAA+BD,EAChCjG,EAAKgH,WAAahH,EAAKxC,EAAI,EAC3B,MAAM,IAAIM,MAAM,oCAEpB,GAAIkC,EAAK4F,kBAAmB,CACxB,IAAK5F,EAAK+F,2BACN,MAAM,IAAIjI,MAAM,4CAEpB,IAAKkC,EAAKkG,6BACN,MAAM,IAAIpI,MAAM,8CAEpB,IAAKkC,EAAKqG,sBACN,MAAM,IAAIvI,MAAM,qCAExB,CAIE,OAHFkC,EAAKiH,cAAYC,EAAAA,EAAAA,GAAA,CACb3B,OAAAA,GACGtB,GACLjE,CACN,CAqOC,OApODlB,EAAAA,EAAAA,GAAAiF,EAAA,EAAAhF,IAAA,mBAAApB,MAGA,WACI,OAAAuJ,EAAAA,EAAAA,GAAA,CACIC,MAAO3G,KAAK+F,UACZG,YAAalG,KAAKkG,YAClBU,MAAO5G,KAAKmG,KACZU,kBAAmB7G,KAAKoG,iBACxBU,iBAAkB9G,KAAKqG,gBACvBU,YAAgC,IAApB/G,KAAKsG,eAAmB5J,EAAYsD,KAAKsG,UACrDtJ,EAAGgD,KAAKhD,EACRgK,WAAYhH,KAAKuG,UACjB1H,KAAMmB,KAAKnB,KACXoI,OAAQjH,KAAKwG,WACVxG,KAAKgG,YAEhB,GACA,CAAAzH,IAAA,qBAAApB,MACA,WACI,OAAAuJ,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,CACIQ,WAAYlH,KAAK+F,WACd/F,KAAKmH,oBACLnH,KAAKyG,aAEhB,GACA,CAAAlI,IAAA,oBAAApB,MAGA,WACI,OAAO6C,KAAKoH,oBAChB,GACA,CAAA7I,IAAA,YAAApB,MAAA,eAAAkK,GAAA5I,EAAAA,EAAAA,IAAAC,EAAAA,EAAAA,KAAAC,MACA,SAAAC,EAAgBvC,EAAUiL,EAAelI,GAAU,IAAAmI,EAAAC,EAAA3I,EAAA4I,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAApJ,EAAAqJ,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAAvL,EAAAK,EAAAmL,EAAA,YAAAlK,EAAAA,EAAAA,KAAAe,MAAA,SAAAC,GAAA,cAAAA,EAAAC,KAAAD,EAAAE,MAAA,OAO1B,GANff,EAAOgK,MAAMC,QAAQxB,GACrBA,EACa,OAAbA,QAAa,IAAbA,OAAa,EAAbA,EAAezI,KACf4I,EAAUoB,MAAMC,QAAQxB,GACxB,CAAC,EACqB,QADpBC,EACW,OAAbD,QAAa,IAAbA,OAAa,EAAbA,EAAeG,eAAO,IAAAF,EAAAA,EAAI,CAAC,EAC3BG,EAAa,CAAC,GAChB1H,KAAKnB,OAAQA,EAAI,CAAAa,EAAAE,KAAA,cACX,IAAItC,MAAM,0CAAyC,OAQ1D,IANGqK,EAAS3H,KAAKmH,oBACbtI,KAAW,OAAJA,QAAI,IAAJA,EAAAA,EAAQ8I,EAAO9I,KACvB+I,EAAiBvL,EAASwD,KAAI,SAACwC,GAAO,MAAM,CAC9CjF,KAAM4F,EAAwBX,EAAQhF,YACtC0L,QAAS1G,EAAQ5E,KACjB2C,KAAMiC,EAAQjC,KACjB,KACYuH,EAAOV,OAAM,CAAAvH,EAAAE,KAAA,gBAAAF,EAAAE,KAAA,GACd,IAAIU,SAAQ,SAAC0I,EAASC,GAC1B,IAAIC,EACAC,GAAW,EACXC,GAAW,EACfR,EAAKS,qBAAmB3C,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAC,CAAC,EACnBiB,GAAM,IACTtL,SAAUuL,KAAclB,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GAErBe,GAAO,IACV6B,QAASC,EAAAA,EACTC,aAAc,SACdC,UAAW,SAACC,GAAU,IAAAC,EAAAC,EAClB,GAA6B,YAAf,QAAVD,EAAAD,EAAM7B,YAAI,IAAA8B,GAAM,QAANC,EAAVD,EAAYE,YAAI,IAAAD,OAAN,EAAVA,EAAAvL,KAAAsL,IAAmC,CACnC,GAAIP,EACA,OAEJA,GAAW,EACXJ,EAAQE,EACZ,KACK,CACD,IAAM7G,EAAUyH,KAAKC,MAAML,EAAM7B,MAE5BqB,IACDA,EAAW,CACPc,GAAI3H,EAAQ2H,GACZC,OAAQ5H,EAAQ4H,OAChBC,QAAS7H,EAAQ6H,QACjBvD,MAAOtE,EAAQsE,MACfwD,QAAS,KAGjB,IACkC7N,EADlCO,GAAAC,EAAAA,EAAAA,GACmBuF,EAAQ8H,SAAO,QAAAC,EAAA,WAAE,IAAzBzB,EAAIrM,EAAAa,MACX,GAAY,MAARwL,EAAc,KAAA0B,EAAAC,EAAAC,EAAAC,EAEDC,EAOQC,EAAAC,EAAAC,EARjBC,EAAS3B,EAASiB,QAAQW,MAAK,SAACC,GAAC,OAAKA,EAAEC,QAAUrC,EAAKqC,KAAK,IAChE,IAAKH,EACDA,EAAS,CACLG,MAAOrC,EAAKqC,MACZC,cAAiC,QAApBR,EAAE9B,EAAKsC,qBAAa,IAAAR,EAAAA,OAAI/N,GAEzCwM,EAASiB,QAAQxB,EAAKqC,OAASH,EAEnC,IAAKA,EAAOxI,QACRwI,EAAOxI,QAAU,CACbjF,KAAgB,QAAZsN,EAAE/B,EAAKuC,aAAK,IAAAR,OAAA,EAAVA,EACAtN,KACN2L,QAA4B,QAArB4B,EAAY,QAAZC,EAAEjC,EAAKuC,aAAK,IAAAN,OAAA,EAAVA,EAAY7B,eAAO,IAAA4B,EAAAA,EAAI,IAGxCE,EAAOxI,QAAQ0G,SAA8B,QAAvBsB,EAAc,QAAdC,EAAI3B,EAAKuC,aAAK,IAAAZ,OAAA,EAAVA,EAAYvB,eAAO,IAAAsB,EAAAA,EAAI,GAIlC,OAAVjL,QAAU,IAAVA,GAAAA,EAAY+L,kBAAqC,QAApBZ,EAAW,QAAXC,EAAC7B,EAAKuC,aAAK,IAAAV,OAAA,EAAVA,EAAYzB,eAAO,IAAAwB,EAAAA,EAAI,GAC9D,CACJ,EAvBA,IAAA1N,EAAAE,MAAAT,EAAAO,EAAAG,KAAAC,MAAAmN,GAwBA,OAAA1M,GAAAb,EAAAc,EAAAD,EAAA,SAAAb,EAAAe,GAAA,EACKwL,GACD/G,EAAQ8H,QAAQiB,OAAM,SAACL,GAAC,OAAwB,MAAnBA,EAAEE,aAAqB,MACpD7B,GAAW,EACXJ,EAAQE,GAEhB,CACJ,KACDmC,OAAM,SAACC,GACDnC,IACDA,GAAW,EACXF,EAAOqC,GAEf,GACJ,IAAE,QAAA5L,EAAAe,GAAAf,EAAAQ,KAAAR,EAAAE,KAAA,wBAAAF,EAAAE,KAAA,GACMI,KAAKqJ,qBAAmB3C,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAC,CAAC,EAC3BiB,GAAM,IACTtL,SAAUuL,IACXH,GAAQ,QAAA/H,EAAAe,GAAAf,EAAAQ,KAAA,QA3ET2H,EAAInI,EAAAe,GAAAqH,EA4EyG,QA5EzGN,EA4E+FK,EAAK0D,aAAK,IAAA/D,EAAAA,EAAI,CAAC,EAA7FO,EAAgBD,EAAnC0D,kBAAoDxD,EAAYF,EAA3B2D,cAA2CxD,EAAWH,EAAzB4D,aACtE3D,IACAL,EAAWK,kBACqB,QAA5BG,EAACR,EAAWK,wBAAgB,IAAAG,EAAAA,EAAI,GAAKH,GAEzCC,IACAN,EAAWM,cAAuC,QAAxBG,EAACT,EAAWM,oBAAY,IAAAG,EAAAA,EAAI,GAAKH,GAE3DC,IACAP,EAAWO,aAAqC,QAAvBG,EAACV,EAAWO,mBAAW,IAAAG,EAAAA,EAAI,GAAKH,GAEvDjJ,EAAc,GAAEqJ,GAAAvL,EAAAA,EAAAA,GACH+K,EAAKsC,SAAO,IAA/B,IAAA9B,EAAAtL,MAAAuL,EAAAD,EAAArL,KAAAC,MAAW0L,EAAIL,EAAAnL,MACLC,EAAyB,QAArBmL,EAAe,QAAfC,EAAGG,EAAKtG,eAAO,IAAAmG,OAAA,EAAZA,EAAcpL,YAAI,IAAAmL,EAAAA,OAAI7L,EAC7Be,EAA4B,QAAxBgL,EAAe,QAAfC,EAAGC,EAAKtG,eAAO,IAAAqG,OAAA,EAAZA,EAAcK,eAAO,IAAAN,EAAAA,EAAI,GACtCzJ,EAAYxB,KAAK,CACbC,KAAAA,EACA4E,QAASa,EAA4B9F,EAAMK,IAElD,OAAAC,GAAA2K,EAAA1K,EAAAD,EAAA,SAAA2K,EAAAzK,GAAA,QAAA8B,EAAAyB,OAAA,SACM,CACHnC,YAAAA,EACAwB,UAAW,CAAEkH,WAAAA,KAChB,yBAAAhI,EAAAb,OAAA,GAAAD,EAAA,UACJ,gBAAAwC,EAAAC,EAAAC,GAAA,OAAA+F,EAAAzG,MAAA,KAAApE,UAAA,EAvHD,IAuHC,CAAA+B,IAAA,2BAAApB,MAAA,eAAAwO,GAAAlN,EAAAA,EAAAA,IAAAC,EAAAA,EAAAA,KAAAC,MACD,SAAAwD,EAA+B9F,GAAQ,IAAAuP,EAAAC,EAAAC,EAAAC,EAAAC,EAAA,YAAAtN,EAAAA,EAAAA,KAAAe,MAAA,SAAA2C,GAAA,cAAAA,EAAAzC,KAAAyC,EAAAxC,MAAA,OAYlC,OAXGgM,EAAa,EACbC,EAAmB,EACnBC,EAAgB,EAE4B,mBAA5CG,EAAAA,EAAAA,IAAwBjM,KAAK+F,YAC7B8F,EAAmB,EACnBC,GAAiB,IAEZG,EAAAA,EAAAA,IAAwBjM,KAAK+F,WAAWmG,WAAW,WACxDL,EAAmB,EACnBC,EAAgB,GACnB1J,EAAAxC,KAAA,EAC6BU,QAAQC,IAAIlE,EAASwD,IAAG,eAAAsM,GAAA1N,EAAAA,EAAAA,IAAAC,EAAAA,EAAAA,KAAAC,MAAC,SAAA6C,EAAOa,GAAO,IAAA+J,EAAAC,EAAA,OAAA3N,EAAAA,EAAAA,KAAAe,MAAA,SAAAkC,GAAA,cAAAA,EAAAhC,KAAAgC,EAAA/B,MAAA,cAAA+B,EAAA/B,KAAA,EACzCoM,EAAKM,aAAajK,EAAQ5E,MAAK,OAEnC,OAFd2O,EAASzK,EAAAzB,KACTmM,EAAQD,EAAYP,GAAoBxJ,EAAQjC,KAAO0L,EAAgB,GAC7EF,GAAcS,EAAM1K,EAAAR,OAAA,SACbkL,GAAK,wBAAA1K,EAAA9C,OAAA,GAAA2C,EAAA,KACf,gBAAAQ,GAAA,OAAAmK,EAAAvL,MAAA,KAAApE,UAAA,EALqD,KAKnD,OALkB,OAAfuP,EAAe3J,EAAAlC,KAAAkC,EAAAjB,OAAA,SAMd,CAAEyK,WAAAA,EAAYG,gBAAAA,IAAiB,wBAAA3J,EAAAvD,OAAA,GAAAsD,EAAA,UACzC,gBAAAJ,GAAA,OAAA4J,EAAA/K,MAAA,KAAApE,UAAA,EArBA,IAsBD,CAAA+B,IAAA,sBAAApB,MAAA,eAAAoP,GAAA9N,EAAAA,EAAAA,IAAAC,EAAAA,EAAAA,KAAAC,MACA,SAAA+D,EAA0B8J,EAAS/E,GAAO,IAAAgF,EAAAhG,EAAAiG,EAAA,OAAAhO,EAAAA,EAAAA,KAAAe,MAAA,SAAAkD,GAAA,cAAAA,EAAAhD,KAAAgD,EAAA/C,MAAA,OA6BrC,OA5BII,KAAK2M,SACAF,EAAWzM,KAAKoF,kBAAiB,WAAA7H,OACtByC,KAAKuF,2BAA0B,yCAAAhI,OAAwCyC,KAAK0F,8BACvF1F,KAAKyG,aAAamG,SAClBnG,EAAe,IAAIoG,EAAAA,eAAanG,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAC,CAAC,EACjC1G,KAAKyG,cAAY,IACpBmG,SAAUH,EACVK,aAAWpG,EAAAA,EAAAA,GAAA,CACPT,QAASjG,KAAKiG,SACXjG,KAAKyG,aAAaqG,gBAG7B9M,KAAK2M,OAAS,IAAII,EAAAA,UAAUtG,IAE1BiG,GAAYhG,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,CACd4C,QAAS0D,EAAAA,QAAStQ,EAAY6M,EAAAA,GAC3BvJ,KAAKyG,aAAaqG,aAClBrF,GAEHzH,KAAKoF,oBACLsH,EAAaO,SAAOvG,EAAAA,EAAAA,GAAA,CAChB,UAAW1G,KAAKoF,mBACbsH,EAAaO,SAEpBP,EAAa/E,QAAMjB,EAAAA,EAAAA,GAAA,CACf,cAAe1G,KAAK6F,uBACjB6G,EAAa/E,SAEvBhF,EAAAxB,OAAA,SACMnB,KAAKkN,OACP7O,KAAK2B,KAAK2M,OAAOQ,qBAAqBC,KAAKpN,KAAK2M,QAASH,EAASE,GAClEW,MAAK,SAACC,GAAG,OAAKA,EAAIzF,IAAI,KAAC,wBAAAlF,EAAA9D,OAAA,GAAA6D,EAAA,UAC/B,gBAAAT,EAAAK,GAAA,OAAAiK,EAAA3L,MAAA,KAAApE,UAAA,EAlCD,IAkCC,CAAA+B,IAAA,WAAApB,MACD,WACI,MAAO,QACX,GACA,CAAAoB,IAAA,oBAAApB,MACA,WAAiC,QAAAoQ,EAAA/Q,UAAAC,OAAZwC,EAAU,IAAA4J,MAAA0E,GAAAC,EAAA,EAAAA,EAAAD,EAAAC,IAAVvO,EAAUuO,GAAAhR,UAAAgR,GAC3B,OAAOvO,EAAWwO,QAAO,SAACC,EAAKlN,GACY,IAAAmN,EAAAC,EAAAC,EAAnCrN,GAAaA,EAAUkH,aACvBgG,EAAIhG,WAAWK,kBAC0B,QADV4F,EAC3BnN,EAAUkH,WAAWK,wBAAgB,IAAA4F,EAAAA,EAAI,EAC7CD,EAAIhG,WAAWM,cAAiD,QAArC4F,EAAIpN,EAAUkH,WAAWM,oBAAY,IAAA4F,EAAAA,EAAI,EACpEF,EAAIhG,WAAWO,aAA+C,QAApC4F,EAAIrN,EAAUkH,WAAWO,mBAAW,IAAA4F,EAAAA,EAAI,GAEtE,OAAOH,CACX,GAAG,CACChG,WAAY,CACRK,iBAAkB,EAClBC,aAAc,EACdC,YAAa,IAGzB,KAAC1E,CAAA,CAlZkB,CAASzF,E","sources":["../node_modules/langchain/dist/memory/base.js","../node_modules/langchain/dist/chat_models/base.js","../node_modules/langchain/dist/chat_models/openai.js"],"sourcesContent":["export class BaseMemory {\n}\n/**\n * This function is used by memory classes to select the input value\n * to use for the memory. If there is only one input value, it is used.\n * If there are multiple input values, the inputKey must be specified.\n */\nexport const getInputValue = (inputValues, inputKey) => {\n    if (inputKey !== undefined) {\n        return inputValues[inputKey];\n    }\n    const keys = Object.keys(inputValues);\n    if (keys.length === 1) {\n        return inputValues[keys[0]];\n    }\n    throw new Error(`input values have ${keys.length} keys, you must specify an input key or pass only 1 key as input`);\n};\n/**\n * This function is used by memory classes to get a string representation\n * of the chat message history, based on the message content and role.\n */\nexport function getBufferString(messages, humanPrefix = \"Human\", aiPrefix = \"AI\") {\n    const string_messages = [];\n    for (const m of messages) {\n        let role;\n        if (m._getType() === \"human\") {\n            role = humanPrefix;\n        }\n        else if (m._getType() === \"ai\") {\n            role = aiPrefix;\n        }\n        else if (m._getType() === \"system\") {\n            role = \"System\";\n        }\n        else if (m._getType() === \"generic\") {\n            role = m.role;\n        }\n        else {\n            throw new Error(`Got unsupported message type: ${m}`);\n        }\n        string_messages.push(`${role}: ${m.text}`);\n    }\n    return string_messages.join(\"\\n\");\n}\n","import { AIChatMessage, RUN_KEY, } from \"../schema/index.js\";\nimport { BaseLanguageModel, } from \"../base_language/index.js\";\nimport { getBufferString } from \"../memory/base.js\";\nimport { CallbackManager, } from \"../callbacks/manager.js\";\nexport class BaseChatModel extends BaseLanguageModel {\n    constructor(fields) {\n        super(fields);\n    }\n    async generate(messages, stop, callbacks) {\n        const generations = [];\n        const llmOutputs = [];\n        const messageStrings = messages.map((messageList) => getBufferString(messageList));\n        const callbackManager_ = await CallbackManager.configure(callbacks, this.callbacks, { verbose: this.verbose });\n        const runManager = await callbackManager_?.handleLLMStart({ name: this._llmType() }, messageStrings);\n        try {\n            const results = await Promise.all(messages.map((messageList) => this._generate(messageList, stop, runManager)));\n            for (const result of results) {\n                if (result.llmOutput) {\n                    llmOutputs.push(result.llmOutput);\n                }\n                generations.push(result.generations);\n            }\n        }\n        catch (err) {\n            await runManager?.handleLLMError(err);\n            throw err;\n        }\n        const output = {\n            generations,\n            llmOutput: llmOutputs.length\n                ? this._combineLLMOutput?.(...llmOutputs)\n                : undefined,\n        };\n        await runManager?.handleLLMEnd(output);\n        Object.defineProperty(output, RUN_KEY, {\n            value: runManager ? { runId: runManager?.runId } : undefined,\n            configurable: true,\n        });\n        return output;\n    }\n    _modelType() {\n        return \"base_chat_model\";\n    }\n    async generatePrompt(promptValues, stop, callbacks) {\n        const promptMessages = promptValues.map((promptValue) => promptValue.toChatMessages());\n        return this.generate(promptMessages, stop, callbacks);\n    }\n    async call(messages, stop, callbacks) {\n        const result = await this.generate([messages], stop, callbacks);\n        const generations = result.generations;\n        return generations[0][0].message;\n    }\n    async callPrompt(promptValue, stop, callbacks) {\n        const promptMessages = promptValue.toChatMessages();\n        return this.call(promptMessages, stop, callbacks);\n    }\n}\nexport class SimpleChatModel extends BaseChatModel {\n    async _generate(messages, stop, runManager) {\n        const text = await this._call(messages, stop, runManager);\n        const message = new AIChatMessage(text);\n        return {\n            generations: [\n                {\n                    text: message.text,\n                    message,\n                },\n            ],\n        };\n    }\n}\n","import { isNode } from \"browser-or-node\";\nimport { Configuration, OpenAIApi, } from \"openai\";\nimport fetchAdapter from \"../util/axios-fetch-adapter.js\";\nimport { BaseChatModel } from \"./base.js\";\nimport { AIChatMessage, ChatMessage, HumanChatMessage, SystemChatMessage, } from \"../schema/index.js\";\nimport { getModelNameForTiktoken } from \"../base_language/count_tokens.js\";\nfunction messageTypeToOpenAIRole(type) {\n    switch (type) {\n        case \"system\":\n            return \"system\";\n        case \"ai\":\n            return \"assistant\";\n        case \"human\":\n            return \"user\";\n        default:\n            throw new Error(`Unknown message type: ${type}`);\n    }\n}\nfunction openAIResponseToChatMessage(role, text) {\n    switch (role) {\n        case \"user\":\n            return new HumanChatMessage(text);\n        case \"assistant\":\n            return new AIChatMessage(text);\n        case \"system\":\n            return new SystemChatMessage(text);\n        default:\n            return new ChatMessage(text, role ?? \"unknown\");\n    }\n}\n/**\n * Wrapper around OpenAI large language models that use the Chat endpoint.\n *\n * To use you should have the `openai` package installed, with the\n * `OPENAI_API_KEY` environment variable set.\n *\n * To use with Azure you should have the `openai` package installed, with the\n * `AZURE_OPENAI_API_KEY`,\n * `AZURE_OPENAI_API_INSTANCE_NAME`,\n * `AZURE_OPENAI_API_DEPLOYMENT_NAME`\n * and `AZURE_OPENAI_API_VERSION` environment variable set.\n *\n * @remarks\n * Any parameters that are valid to be passed to {@link\n * https://platform.openai.com/docs/api-reference/chat/create |\n * `openai.createCompletion`} can be passed through {@link modelKwargs}, even\n * if not explicitly available on this class.\n */\nexport class ChatOpenAI extends BaseChatModel {\n    constructor(fields, configuration) {\n        super(fields ?? {});\n        Object.defineProperty(this, \"temperature\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: 1\n        });\n        Object.defineProperty(this, \"topP\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: 1\n        });\n        Object.defineProperty(this, \"frequencyPenalty\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: 0\n        });\n        Object.defineProperty(this, \"presencePenalty\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: 0\n        });\n        Object.defineProperty(this, \"n\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: 1\n        });\n        Object.defineProperty(this, \"logitBias\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"modelName\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: \"gpt-3.5-turbo\"\n        });\n        Object.defineProperty(this, \"modelKwargs\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"stop\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"timeout\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"streaming\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: false\n        });\n        Object.defineProperty(this, \"maxTokens\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"azureOpenAIApiVersion\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"azureOpenAIApiKey\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"azureOpenAIApiInstanceName\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"azureOpenAIApiDeploymentName\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"client\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"clientConfig\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        const apiKey = fields?.openAIApiKey ??\n            (typeof process !== \"undefined\"\n                ? // eslint-disable-next-line no-process-env\n                    process.env?.OPENAI_API_KEY\n                : undefined);\n        const azureApiKey = fields?.azureOpenAIApiKey ??\n            (typeof process !== \"undefined\"\n                ? // eslint-disable-next-line no-process-env\n                    process.env?.AZURE_OPENAI_API_KEY\n                : undefined);\n        if (!azureApiKey && !apiKey) {\n            throw new Error(\"(Azure) OpenAI API key not found\");\n        }\n        const azureApiInstanceName = fields?.azureOpenAIApiInstanceName ??\n            (typeof process !== \"undefined\"\n                ? // eslint-disable-next-line no-process-env\n                    process.env?.AZURE_OPENAI_API_INSTANCE_NAME\n                : undefined);\n        const azureApiDeploymentName = fields?.azureOpenAIApiDeploymentName ??\n            (typeof process !== \"undefined\"\n                ? // eslint-disable-next-line no-process-env\n                    process.env?.AZURE_OPENAI_API_DEPLOYMENT_NAME\n                : undefined);\n        const azureApiVersion = fields?.azureOpenAIApiVersion ??\n            (typeof process !== \"undefined\"\n                ? // eslint-disable-next-line no-process-env\n                    process.env?.AZURE_OPENAI_API_VERSION\n                : undefined);\n        this.modelName = fields?.modelName ?? this.modelName;\n        this.modelKwargs = fields?.modelKwargs ?? {};\n        this.timeout = fields?.timeout;\n        this.temperature = fields?.temperature ?? this.temperature;\n        this.topP = fields?.topP ?? this.topP;\n        this.frequencyPenalty = fields?.frequencyPenalty ?? this.frequencyPenalty;\n        this.presencePenalty = fields?.presencePenalty ?? this.presencePenalty;\n        this.maxTokens = fields?.maxTokens;\n        this.n = fields?.n ?? this.n;\n        this.logitBias = fields?.logitBias;\n        this.stop = fields?.stop;\n        this.streaming = fields?.streaming ?? false;\n        this.azureOpenAIApiVersion = azureApiVersion;\n        this.azureOpenAIApiKey = azureApiKey;\n        this.azureOpenAIApiInstanceName = azureApiInstanceName;\n        this.azureOpenAIApiDeploymentName = azureApiDeploymentName;\n        if (this.streaming && this.n > 1) {\n            throw new Error(\"Cannot stream results when n > 1\");\n        }\n        if (this.azureOpenAIApiKey) {\n            if (!this.azureOpenAIApiInstanceName) {\n                throw new Error(\"Azure OpenAI API instance name not found\");\n            }\n            if (!this.azureOpenAIApiDeploymentName) {\n                throw new Error(\"Azure OpenAI API deployment name not found\");\n            }\n            if (!this.azureOpenAIApiVersion) {\n                throw new Error(\"Azure OpenAI API version not found\");\n            }\n        }\n        this.clientConfig = {\n            apiKey,\n            ...configuration,\n        };\n    }\n    /**\n     * Get the parameters used to invoke the model\n     */\n    invocationParams() {\n        return {\n            model: this.modelName,\n            temperature: this.temperature,\n            top_p: this.topP,\n            frequency_penalty: this.frequencyPenalty,\n            presence_penalty: this.presencePenalty,\n            max_tokens: this.maxTokens === -1 ? undefined : this.maxTokens,\n            n: this.n,\n            logit_bias: this.logitBias,\n            stop: this.stop,\n            stream: this.streaming,\n            ...this.modelKwargs,\n        };\n    }\n    /** @ignore */\n    _identifyingParams() {\n        return {\n            model_name: this.modelName,\n            ...this.invocationParams(),\n            ...this.clientConfig,\n        };\n    }\n    /**\n     * Get the identifying parameters for the model\n     */\n    identifyingParams() {\n        return this._identifyingParams();\n    }\n    /** @ignore */\n    async _generate(messages, stopOrOptions, runManager) {\n        const stop = Array.isArray(stopOrOptions)\n            ? stopOrOptions\n            : stopOrOptions?.stop;\n        const options = Array.isArray(stopOrOptions)\n            ? {}\n            : stopOrOptions?.options ?? {};\n        const tokenUsage = {};\n        if (this.stop && stop) {\n            throw new Error(\"Stop found in input and default params\");\n        }\n        const params = this.invocationParams();\n        params.stop = stop ?? params.stop;\n        const messagesMapped = messages.map((message) => ({\n            role: messageTypeToOpenAIRole(message._getType()),\n            content: message.text,\n            name: message.name,\n        }));\n        const data = params.stream\n            ? await new Promise((resolve, reject) => {\n                let response;\n                let rejected = false;\n                let resolved = false;\n                this.completionWithRetry({\n                    ...params,\n                    messages: messagesMapped,\n                }, {\n                    ...options,\n                    adapter: fetchAdapter,\n                    responseType: \"stream\",\n                    onmessage: (event) => {\n                        if (event.data?.trim?.() === \"[DONE]\") {\n                            if (resolved) {\n                                return;\n                            }\n                            resolved = true;\n                            resolve(response);\n                        }\n                        else {\n                            const message = JSON.parse(event.data);\n                            // on the first message set the response properties\n                            if (!response) {\n                                response = {\n                                    id: message.id,\n                                    object: message.object,\n                                    created: message.created,\n                                    model: message.model,\n                                    choices: [],\n                                };\n                            }\n                            // on all messages, update choice\n                            for (const part of message.choices) {\n                                if (part != null) {\n                                    let choice = response.choices.find((c) => c.index === part.index);\n                                    if (!choice) {\n                                        choice = {\n                                            index: part.index,\n                                            finish_reason: part.finish_reason ?? undefined,\n                                        };\n                                        response.choices[part.index] = choice;\n                                    }\n                                    if (!choice.message) {\n                                        choice.message = {\n                                            role: part.delta\n                                                ?.role,\n                                            content: part.delta?.content ?? \"\",\n                                        };\n                                    }\n                                    choice.message.content += part.delta?.content ?? \"\";\n                                    // TODO this should pass part.index to the callback\n                                    // when that's supported there\n                                    // eslint-disable-next-line no-void\n                                    void runManager?.handleLLMNewToken(part.delta?.content ?? \"\");\n                                }\n                            }\n                            // when all messages are finished, resolve\n                            if (!resolved &&\n                                message.choices.every((c) => c.finish_reason != null)) {\n                                resolved = true;\n                                resolve(response);\n                            }\n                        }\n                    },\n                }).catch((error) => {\n                    if (!rejected) {\n                        rejected = true;\n                        reject(error);\n                    }\n                });\n            })\n            : await this.completionWithRetry({\n                ...params,\n                messages: messagesMapped,\n            }, options);\n        const { completion_tokens: completionTokens, prompt_tokens: promptTokens, total_tokens: totalTokens, } = data.usage ?? {};\n        if (completionTokens) {\n            tokenUsage.completionTokens =\n                (tokenUsage.completionTokens ?? 0) + completionTokens;\n        }\n        if (promptTokens) {\n            tokenUsage.promptTokens = (tokenUsage.promptTokens ?? 0) + promptTokens;\n        }\n        if (totalTokens) {\n            tokenUsage.totalTokens = (tokenUsage.totalTokens ?? 0) + totalTokens;\n        }\n        const generations = [];\n        for (const part of data.choices) {\n            const role = part.message?.role ?? undefined;\n            const text = part.message?.content ?? \"\";\n            generations.push({\n                text,\n                message: openAIResponseToChatMessage(role, text),\n            });\n        }\n        return {\n            generations,\n            llmOutput: { tokenUsage },\n        };\n    }\n    async getNumTokensFromMessages(messages) {\n        let totalCount = 0;\n        let tokensPerMessage = 0;\n        let tokensPerName = 0;\n        // From: https://github.com/openai/openai-cookbook/blob/main/examples/How_to_format_inputs_to_ChatGPT_models.ipynb\n        if (getModelNameForTiktoken(this.modelName) === \"gpt-3.5-turbo\") {\n            tokensPerMessage = 4;\n            tokensPerName = -1;\n        }\n        else if (getModelNameForTiktoken(this.modelName).startsWith(\"gpt-4\")) {\n            tokensPerMessage = 3;\n            tokensPerName = 1;\n        }\n        const countPerMessage = await Promise.all(messages.map(async (message) => {\n            const textCount = await this.getNumTokens(message.text);\n            const count = textCount + tokensPerMessage + (message.name ? tokensPerName : 0);\n            totalCount += count;\n            return count;\n        }));\n        return { totalCount, countPerMessage };\n    }\n    /** @ignore */\n    async completionWithRetry(request, options) {\n        if (!this.client) {\n            const endpoint = this.azureOpenAIApiKey\n                ? `https://${this.azureOpenAIApiInstanceName}.openai.azure.com/openai/deployments/${this.azureOpenAIApiDeploymentName}`\n                : this.clientConfig.basePath;\n            const clientConfig = new Configuration({\n                ...this.clientConfig,\n                basePath: endpoint,\n                baseOptions: {\n                    timeout: this.timeout,\n                    ...this.clientConfig.baseOptions,\n                },\n            });\n            this.client = new OpenAIApi(clientConfig);\n        }\n        const axiosOptions = {\n            adapter: isNode ? undefined : fetchAdapter,\n            ...this.clientConfig.baseOptions,\n            ...options,\n        };\n        if (this.azureOpenAIApiKey) {\n            axiosOptions.headers = {\n                \"api-key\": this.azureOpenAIApiKey,\n                ...axiosOptions.headers,\n            };\n            axiosOptions.params = {\n                \"api-version\": this.azureOpenAIApiVersion,\n                ...axiosOptions.params,\n            };\n        }\n        return this.caller\n            .call(this.client.createChatCompletion.bind(this.client), request, axiosOptions)\n            .then((res) => res.data);\n    }\n    _llmType() {\n        return \"openai\";\n    }\n    /** @ignore */\n    _combineLLMOutput(...llmOutputs) {\n        return llmOutputs.reduce((acc, llmOutput) => {\n            if (llmOutput && llmOutput.tokenUsage) {\n                acc.tokenUsage.completionTokens +=\n                    llmOutput.tokenUsage.completionTokens ?? 0;\n                acc.tokenUsage.promptTokens += llmOutput.tokenUsage.promptTokens ?? 0;\n                acc.tokenUsage.totalTokens += llmOutput.tokenUsage.totalTokens ?? 0;\n            }\n            return acc;\n        }, {\n            tokenUsage: {\n                completionTokens: 0,\n                promptTokens: 0,\n                totalTokens: 0,\n            },\n        });\n    }\n}\n"],"names":["getBufferString","messages","_step","humanPrefix","arguments","length","undefined","aiPrefix","string_messages","_iterator","_createForOfIteratorHelper","s","n","done","m","value","role","_getType","Error","concat","push","text","err","e","f","join","BaseChatModel","_BaseLanguageModel","_inherits","_super","_createSuper","fields","_classCallCheck","call","_createClass","key","_generate","_asyncToGenerator","_regeneratorRuntime","mark","_callee","stop","callbacks","_this$_combineLLMOutp","generations","llmOutputs","messageStrings","callbackManager_","runManager","results","result","output","_this","wrap","_context","prev","next","map","messageList","CallbackManager","this","verbose","sent","handleLLMStart","name","_llmType","Promise","all","llmOutput","t0","handleLLMError","_combineLLMOutput","apply","handleLLMEnd","Object","defineProperty","RUN_KEY","runId","configurable","abrupt","_x","_x2","_x3","_generatePrompt","_callee2","promptValues","promptMessages","_context2","promptValue","toChatMessages","generate","_x4","_x5","_x6","_call","_callee3","_context3","message","_x7","_x8","_x9","_callPrompt","_callee4","_context4","_x10","_x11","_x12","BaseLanguageModel","messageTypeToOpenAIRole","type","openAIResponseToChatMessage","HumanChatMessage","AIChatMessage","SystemChatMessage","ChatMessage","ChatOpenAI","_BaseChatModel","configuration","_fields$openAIApiKey","_process$env","_fields$azureOpenAIAp","_process$env2","_fields$azureOpenAIAp2","_process$env3","_fields$azureOpenAIAp3","_process$env4","_fields$azureOpenAIAp4","_process$env5","_fields$modelName","_fields$modelKwargs","_fields$temperature","_fields$topP","_fields$frequencyPena","_fields$presencePenal","_fields$n","_fields$streaming","_assertThisInitialized","enumerable","writable","apiKey","openAIApiKey","process","OPENAI_API_KEY","azureApiKey","azureOpenAIApiKey","AZURE_OPENAI_API_KEY","azureApiInstanceName","azureOpenAIApiInstanceName","AZURE_OPENAI_API_INSTANCE_NAME","azureApiDeploymentName","azureOpenAIApiDeploymentName","AZURE_OPENAI_API_DEPLOYMENT_NAME","azureApiVersion","azureOpenAIApiVersion","AZURE_OPENAI_API_VERSION","modelName","modelKwargs","timeout","temperature","topP","frequencyPenalty","presencePenalty","maxTokens","logitBias","streaming","clientConfig","_objectSpread","model","top_p","frequency_penalty","presence_penalty","max_tokens","logit_bias","stream","model_name","invocationParams","_identifyingParams","_generate2","stopOrOptions","_stopOrOptions$option","_data$usage","options","tokenUsage","params","messagesMapped","data","_ref","completionTokens","promptTokens","totalTokens","_tokenUsage$completio","_tokenUsage$promptTok","_tokenUsage$totalToke","_iterator2","_step2","_part$message$role","_part$message","_part$message$content","_part$message2","part","_this2","Array","isArray","content","resolve","reject","response","rejected","resolved","completionWithRetry","adapter","fetchAdapter","responseType","onmessage","event","_event$data","_event$data$trim","trim","JSON","parse","id","object","created","choices","_loop","_part$delta$content2","_part$delta3","_part$delta$content3","_part$delta4","_part$finish_reason","_part$delta","_part$delta$content","_part$delta2","choice","find","c","index","finish_reason","delta","handleLLMNewToken","every","catch","error","usage","completion_tokens","prompt_tokens","total_tokens","_getNumTokensFromMessages","totalCount","tokensPerMessage","tokensPerName","countPerMessage","_this3","getModelNameForTiktoken","startsWith","_ref2","textCount","count","getNumTokens","_completionWithRetry","request","endpoint","axiosOptions","client","basePath","Configuration","baseOptions","OpenAIApi","isNode","headers","caller","createChatCompletion","bind","then","res","_len","_key","reduce","acc","_llmOutput$tokenUsage","_llmOutput$tokenUsage2","_llmOutput$tokenUsage3"],"sourceRoot":""}